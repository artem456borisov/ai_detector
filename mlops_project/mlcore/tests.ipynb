{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc283e8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 7896)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m../../data/subtaskC_train_dev.jsonl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.4/lib/python3.12/json/__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.4/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.4/lib/python3.12/json/decoder.py:340\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 2 column 1 (char 7896)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('../../data/subtaskC_train_dev.jsonl', 'rb') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8e66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7e5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/Users/ruanwko/Downloads/SubtaskA.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for pos, json_str in enumerate(json_list):\n",
    "    json_list[pos] = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6ece55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12dcab93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "human      65177\n",
       "chatGPT    16892\n",
       "gpt4       14344\n",
       "davinci    14340\n",
       "bloomz     14332\n",
       "dolly      14046\n",
       "cohere     13678\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6767df6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label', 'source', 'model', 'parallel', 'cohere_0', 'chatGPT_0',\n",
       "       'davinci_0', 'dolly_0', 'bloomz_0', 'gpt4_0', 'no_0', 'cohere_10',\n",
       "       'chatGPT_10', 'davinci_10', 'dolly_10', 'bloomz_10', 'gpt4_10', 'no_10',\n",
       "       'cohere_30', 'chatGPT_30', 'davinci_30', 'dolly_30', 'bloomz_30',\n",
       "       'gpt4_30', 'no_30', 'cohere_55', 'chatGPT_55', 'davinci_55', 'dolly_55',\n",
       "       'bloomz_55', 'gpt4_55', 'no_55', 'cohere_75', 'chatGPT_75',\n",
       "       'davinci_75', 'dolly_75', 'bloomz_75', 'gpt4_75', 'no_75'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "335c6879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>model</th>\n",
       "      <th>parallel</th>\n",
       "      <th>cohere_0</th>\n",
       "      <th>chatGPT_0</th>\n",
       "      <th>davinci_0</th>\n",
       "      <th>dolly_0</th>\n",
       "      <th>bloomz_0</th>\n",
       "      <th>...</th>\n",
       "      <th>bloomz_55</th>\n",
       "      <th>gpt4_55</th>\n",
       "      <th>no_55</th>\n",
       "      <th>cohere_75</th>\n",
       "      <th>chatGPT_75</th>\n",
       "      <th>davinci_75</th>\n",
       "      <th>dolly_75</th>\n",
       "      <th>bloomz_75</th>\n",
       "      <th>gpt4_75</th>\n",
       "      <th>no_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We consider a system of many polymers in solut...</td>\n",
       "      <td>1</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>cohere</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We present a catalog of 66 YSOs in the Serpens...</td>\n",
       "      <td>1</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>cohere</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectroscopic Observations of the Intermediate...</td>\n",
       "      <td>1</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>cohere</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We present a new class of stochastic Lie group...</td>\n",
       "      <td>1</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>cohere</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALMA as the ideal probe of the solar chromosph...</td>\n",
       "      <td>1</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>cohere</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152804</th>\n",
       "      <td>The main results presented in this dissertati...</td>\n",
       "      <td>0</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152805</th>\n",
       "      <td>Fine-grained sketch-based image retrieval (FG...</td>\n",
       "      <td>0</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152806</th>\n",
       "      <td>We present the derivation of the NNLO two-par...</td>\n",
       "      <td>0</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152807</th>\n",
       "      <td>The principle of optimism in the face of unce...</td>\n",
       "      <td>0</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152808</th>\n",
       "      <td>We consider the setting of prediction with ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152809 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label source  \\\n",
       "0       We consider a system of many polymers in solut...      1  arxiv   \n",
       "1       We present a catalog of 66 YSOs in the Serpens...      1  arxiv   \n",
       "2       Spectroscopic Observations of the Intermediate...      1  arxiv   \n",
       "3       We present a new class of stochastic Lie group...      1  arxiv   \n",
       "4       ALMA as the ideal probe of the solar chromosph...      1  arxiv   \n",
       "...                                                   ...    ...    ...   \n",
       "152804   The main results presented in this dissertati...      0  arxiv   \n",
       "152805   Fine-grained sketch-based image retrieval (FG...      0  arxiv   \n",
       "152806   We present the derivation of the NNLO two-par...      0  arxiv   \n",
       "152807   The principle of optimism in the face of unce...      0  arxiv   \n",
       "152808   We consider the setting of prediction with ex...      0  arxiv   \n",
       "\n",
       "         model  parallel cohere_0 chatGPT_0 davinci_0 dolly_0 bloomz_0  ...  \\\n",
       "0       cohere      True     test     valid     valid   valid    valid  ...   \n",
       "1       cohere      True     test     train     train   train    train  ...   \n",
       "2       cohere      True     test     valid     valid   valid    valid  ...   \n",
       "3       cohere      True     test     train     train   train    train  ...   \n",
       "4       cohere      True     test     valid     valid   valid    valid  ...   \n",
       "...        ...       ...      ...       ...       ...     ...      ...  ...   \n",
       "152804   human     False    train     valid     train   train    train  ...   \n",
       "152805   human     False    train     train     train   train    valid  ...   \n",
       "152806   human     False    train     train     train   train    valid  ...   \n",
       "152807   human     False    train     train     train   train    train  ...   \n",
       "152808   human     False    train     valid     train   train    valid  ...   \n",
       "\n",
       "       bloomz_55 gpt4_55  no_55 cohere_75 chatGPT_75 davinci_75 dolly_75  \\\n",
       "0          train   train  train      test      train      train    train   \n",
       "1          train   train  train      test      train      train    train   \n",
       "2          train   train   test      test      train      train    train   \n",
       "3          train   train  train      test      train      train    train   \n",
       "4          train   train  train      test      valid      valid    train   \n",
       "...          ...     ...    ...       ...        ...        ...      ...   \n",
       "152804     train   train  train     train      train      train    train   \n",
       "152805     train   train  train     train      train      train    train   \n",
       "152806     train   valid  valid     train      valid      train    train   \n",
       "152807     train   valid  train     valid      train      train    valid   \n",
       "152808     train   train  train     train      train      train    train   \n",
       "\n",
       "       bloomz_75 gpt4_75  no_75  \n",
       "0          train   train  valid  \n",
       "1          train   train  valid  \n",
       "2          train   train  train  \n",
       "3          train   train  train  \n",
       "4          valid   valid  train  \n",
       "...          ...     ...    ...  \n",
       "152804     train   train  valid  \n",
       "152805     valid   train  train  \n",
       "152806     train   train  valid  \n",
       "152807     train   valid  valid  \n",
       "152808     train   train  train  \n",
       "\n",
       "[152809 rows x 40 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2f8bde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1024)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b794b1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dae6a6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:2000].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5127c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_1 = df[df.label == 1].sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "316ed8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_2 = df[df.label == 0].sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9eca7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.concat([demo_1,demo_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "175c05ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>model</th>\n",
       "      <th>parallel</th>\n",
       "      <th>cohere_0</th>\n",
       "      <th>chatGPT_0</th>\n",
       "      <th>davinci_0</th>\n",
       "      <th>dolly_0</th>\n",
       "      <th>bloomz_0</th>\n",
       "      <th>...</th>\n",
       "      <th>bloomz_55</th>\n",
       "      <th>gpt4_55</th>\n",
       "      <th>no_55</th>\n",
       "      <th>cohere_75</th>\n",
       "      <th>chatGPT_75</th>\n",
       "      <th>davinci_75</th>\n",
       "      <th>dolly_75</th>\n",
       "      <th>bloomz_75</th>\n",
       "      <th>gpt4_75</th>\n",
       "      <th>no_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93294</th>\n",
       "      <td>Ruth Gregory is a renowned American botanist a...</td>\n",
       "      <td>1</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47322</th>\n",
       "      <td>\\nHow to Make a Bee Costume\\nA bee costume is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>cohere</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7277</th>\n",
       "      <td>Himmatsinhji M. K. was an Indian journalist, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>cohere</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22476</th>\n",
       "      <td>We present a method of analyzing luminosity fu...</td>\n",
       "      <td>1</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>davinci</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77460</th>\n",
       "      <td>\\nThis paper presents a novel method for group...</td>\n",
       "      <td>1</td>\n",
       "      <td>peerread</td>\n",
       "      <td>davinci</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110409</th>\n",
       "      <td>Lots of pieces here, I’ll highlight the ones u...</td>\n",
       "      <td>0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124255</th>\n",
       "      <td>Before touching a clean medical mask, wash yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146264</th>\n",
       "      <td>The recent discoveries of terrestrial exoplan...</td>\n",
       "      <td>0</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120246</th>\n",
       "      <td>Bleach is one way to disinfect it.\\n, You sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8853</th>\n",
       "      <td>The Tampa Bay Rays 2012 season was the team's ...</td>\n",
       "      <td>0</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>human</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label     source  \\\n",
       "93294   Ruth Gregory is a renowned American botanist a...      1  wikipedia   \n",
       "47322   \\nHow to Make a Bee Costume\\nA bee costume is ...      1    wikihow   \n",
       "7277     Himmatsinhji M. K. was an Indian journalist, ...      1  wikipedia   \n",
       "22476   We present a method of analyzing luminosity fu...      1      arxiv   \n",
       "77460   \\nThis paper presents a novel method for group...      1   peerread   \n",
       "...                                                   ...    ...        ...   \n",
       "110409  Lots of pieces here, I’ll highlight the ones u...      0     reddit   \n",
       "124255   Before touching a clean medical mask, wash yo...      0    wikihow   \n",
       "146264   The recent discoveries of terrestrial exoplan...      0      arxiv   \n",
       "120246   Bleach is one way to disinfect it.\\n, You sho...      0    wikihow   \n",
       "8853    The Tampa Bay Rays 2012 season was the team's ...      0  wikipedia   \n",
       "\n",
       "          model  parallel cohere_0 chatGPT_0 davinci_0 dolly_0 bloomz_0  ...  \\\n",
       "93294      gpt4      True    train     valid     train   train    train  ...   \n",
       "47322    cohere      True     test     train     train   train    train  ...   \n",
       "7277     cohere      True     test     train     train   train    train  ...   \n",
       "22476   davinci      True    train     valid      test   train    train  ...   \n",
       "77460   davinci      True    train     train      test   train    train  ...   \n",
       "...         ...       ...      ...       ...       ...     ...      ...  ...   \n",
       "110409    human     False    train     train     train   train    train  ...   \n",
       "124255    human     False    train     train     train   train    train  ...   \n",
       "146264    human     False    valid     train     train   valid    train  ...   \n",
       "120246    human     False    valid     train     train   train    train  ...   \n",
       "8853      human      True     test      test      test    test     test  ...   \n",
       "\n",
       "       bloomz_55 gpt4_55  no_55 cohere_75 chatGPT_75 davinci_75 dolly_75  \\\n",
       "93294      train    test  train     train      train      train    train   \n",
       "47322      train   train  train      test      train      train    valid   \n",
       "7277       valid   valid  train      test      train      train    train   \n",
       "22476      train   train   test     train      train       test    train   \n",
       "77460      valid   train   test     train      train       test    valid   \n",
       "...          ...     ...    ...       ...        ...        ...      ...   \n",
       "110409     train   valid  train     valid      train      train    train   \n",
       "124255     valid   train   test     train      valid      train    train   \n",
       "146264     valid   train  train     train      train      train    train   \n",
       "120246     train   train  train     train      train      valid    train   \n",
       "8853        test    test  train      test       test       test     test   \n",
       "\n",
       "       bloomz_75 gpt4_75  no_75  \n",
       "93294      train    test  train  \n",
       "47322      train   train  train  \n",
       "7277       train   train   test  \n",
       "22476      train   train  train  \n",
       "77460      train   train  train  \n",
       "...          ...     ...    ...  \n",
       "110409     train   train  valid  \n",
       "124255     train   train  train  \n",
       "146264     train   train  valid  \n",
       "120246     valid   valid   test  \n",
       "8853        test    test  valid  \n",
       "\n",
       "[2000 rows x 40 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b94ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.to_csv('demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90233d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bffba260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruanwko/Library/Caches/pypoetry/virtualenvs/mlops-project-zy5VbVj4-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 136919.61it/s]\n",
      "Generating embeddings:   0%|          | 0/250 [00:00<?, ?batch/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Generating embeddings: 100%|██████████| 250/250 [04:43<00:00,  1.13s/batch]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     29\u001b[39m     result += \u001b[38;5;28mlist\u001b[39m(torch.tensor(dense_vecs))\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# Apply mean pooling (average across token dimension)\u001b[39;00m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# dense_vecs shape: [batch_size, sequence_length, embedding_dim]\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# After mean pooling: [batch_size, embedding_dim]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Store the pooled embeddings\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Combine results\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m final_embeddings = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(final_embeddings)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m embeddings with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_embeddings.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/mlops-project-zy5VbVj4-py3.12/lib/python3.12/site-packages/numpy/_core/shape_base.py:290\u001b[39m, in \u001b[36mvstack\u001b[39m\u001b[34m(tup, dtype, casting)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    289\u001b[39m     arrs = (arrs,)\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import io\n",
    "import torch\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "# Load your model\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "batch_size = 8\n",
    "all_embeddings = []\n",
    "\n",
    "# Get total number of batches for progress bar\n",
    "total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "result = []\n",
    "\n",
    "# Process with a progress bar\n",
    "for i in tqdm(range(0, len(df), batch_size), \n",
    "               desc=\"Generating embeddings\", \n",
    "               total=total_batches,\n",
    "               unit=\"batch\"):\n",
    "    batch = df.text.tolist()[i:i + batch_size]\n",
    "    # Encode the batch\n",
    "    with io.StringIO() as buf, redirect_stdout(buf), redirect_stderr(buf):\n",
    "        batch_output = model.encode(batch, batch_size=len(batch), max_length=500, return_dense=True)\n",
    "    \n",
    "    # Extract dense vectors\n",
    "    dense_vecs = batch_output['dense_vecs']\n",
    "    result += list(torch.tensor(dense_vecs))\n",
    "    # Apply mean pooling (average across token dimension)\n",
    "    # dense_vecs shape: [batch_size, sequence_length, embedding_dim]\n",
    "    # After mean pooling: [batch_size, embedding_dim]\n",
    "    # pooled_embeddings = np.mean(dense_vecs, axis=1)\n",
    "    \n",
    "    # Store the pooled embeddings\n",
    "# Combine results\n",
    "final_embeddings = np.vstack(all_embeddings)\n",
    "print(f\"Generated {len(final_embeddings)} embeddings with shape {final_embeddings.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2bffc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embeddings'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "978d6aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0879, -0.0094, -0.0191,  ..., -0.0440,  0.0073,  0.0044],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ac3de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open('train_m4gt.pkl', 'wb') as f:\n",
    "    dill.dump(df[df.cohere_0 == 'train'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a50c7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_m4gt.pkl', 'wb') as f:\n",
    "    dill.dump(df[df.cohere_0 == 'valid'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d94383ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_m4gt.pkl', 'wb') as f:\n",
    "    dill.dump(df[df.cohere_0 == 'test'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd3796e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>model</th>\n",
       "      <th>parallel</th>\n",
       "      <th>cohere_0</th>\n",
       "      <th>chatGPT_0</th>\n",
       "      <th>davinci_0</th>\n",
       "      <th>dolly_0</th>\n",
       "      <th>bloomz_0</th>\n",
       "      <th>...</th>\n",
       "      <th>gpt4_55</th>\n",
       "      <th>no_55</th>\n",
       "      <th>cohere_75</th>\n",
       "      <th>chatGPT_75</th>\n",
       "      <th>davinci_75</th>\n",
       "      <th>dolly_75</th>\n",
       "      <th>bloomz_75</th>\n",
       "      <th>gpt4_75</th>\n",
       "      <th>no_75</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43673</th>\n",
       "      <td>We present VLT/VIMOS integral field spectrosco...</td>\n",
       "      <td>1</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>bloomz</td>\n",
       "      <td>True</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>[tensor(-0.0603, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101310</th>\n",
       "      <td>The paper titled \"Deep Predictive Coding Netwo...</td>\n",
       "      <td>1</td>\n",
       "      <td>peerread</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>True</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>[tensor(-0.0255, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27388</th>\n",
       "      <td>Lo fiolairé is a songbird species in the famil...</td>\n",
       "      <td>1</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>dolly</td>\n",
       "      <td>True</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>test</td>\n",
       "      <td>[tensor(-0.0048, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28735</th>\n",
       "      <td>Install Ubuntu server., Install subversion., C...</td>\n",
       "      <td>1</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>dolly</td>\n",
       "      <td>True</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[tensor(-0.0266, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14648</th>\n",
       "      <td>How to Program in Visual Basic.NET (VB.NET)'\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>davinci</td>\n",
       "      <td>True</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[tensor(-0.0038, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140138</th>\n",
       "      <td>Efficient bug triaging procedures are an impo...</td>\n",
       "      <td>0</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[tensor(-0.0692, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132646</th>\n",
       "      <td>Samuel English (18 August 1908 – 12 April 1967...</td>\n",
       "      <td>0</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>...</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>test</td>\n",
       "      <td>[tensor(0.0010, dtype=torch.float16), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145951</th>\n",
       "      <td>The calibrations of star formation rate (SFR)...</td>\n",
       "      <td>0</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[tensor(0.0049, dtype=torch.float16), tensor(-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146264</th>\n",
       "      <td>The recent discoveries of terrestrial exoplan...</td>\n",
       "      <td>0</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>[tensor(-0.0703, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120246</th>\n",
       "      <td>Bleach is one way to disinfect it.\\n, You sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>human</td>\n",
       "      <td>False</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>train</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>test</td>\n",
       "      <td>[tensor(-0.0141, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label     source  \\\n",
       "43673   We present VLT/VIMOS integral field spectrosco...      1      arxiv   \n",
       "101310  The paper titled \"Deep Predictive Coding Netwo...      1   peerread   \n",
       "27388   Lo fiolairé is a songbird species in the famil...      1  wikipedia   \n",
       "28735   Install Ubuntu server., Install subversion., C...      1    wikihow   \n",
       "14648   How to Program in Visual Basic.NET (VB.NET)'\\n...      1    wikihow   \n",
       "...                                                   ...    ...        ...   \n",
       "140138   Efficient bug triaging procedures are an impo...      0      arxiv   \n",
       "132646  Samuel English (18 August 1908 – 12 April 1967...      0  wikipedia   \n",
       "145951   The calibrations of star formation rate (SFR)...      0      arxiv   \n",
       "146264   The recent discoveries of terrestrial exoplan...      0      arxiv   \n",
       "120246   Bleach is one way to disinfect it.\\n, You sho...      0    wikihow   \n",
       "\n",
       "          model  parallel cohere_0 chatGPT_0 davinci_0 dolly_0 bloomz_0  ...  \\\n",
       "43673    bloomz      True    valid     valid     train   train     test  ...   \n",
       "101310     gpt4      True    valid     train     train   train    train  ...   \n",
       "27388     dolly      True    valid     train     train    test    train  ...   \n",
       "28735     dolly      True    valid     train     train    test    train  ...   \n",
       "14648   davinci      True    valid     train      test   train    train  ...   \n",
       "...         ...       ...      ...       ...       ...     ...      ...  ...   \n",
       "140138    human     False    valid     train     train   valid    train  ...   \n",
       "132646    human     False    valid     train     train   train    valid  ...   \n",
       "145951    human     False    valid     train     train   valid    train  ...   \n",
       "146264    human     False    valid     train     train   valid    train  ...   \n",
       "120246    human     False    valid     train     train   train    train  ...   \n",
       "\n",
       "       gpt4_55  no_55 cohere_75 chatGPT_75 davinci_75 dolly_75 bloomz_75  \\\n",
       "43673    train  train     train      train      train    train      test   \n",
       "101310    test  train     valid      train      train    valid     train   \n",
       "27388    train  train     train      train      train     test     valid   \n",
       "28735    train  train     train      train      train     test     train   \n",
       "14648    train  train     train      train       test    train     train   \n",
       "...        ...    ...       ...        ...        ...      ...       ...   \n",
       "140138   train  valid     train      train      train    train     train   \n",
       "132646   valid  train     valid      train      train    train     train   \n",
       "145951   train   test     train      train      train    train     train   \n",
       "146264   train  train     train      train      train    train     train   \n",
       "120246   train  train     train      train      valid    train     valid   \n",
       "\n",
       "       gpt4_75  no_75                                         embeddings  \n",
       "43673    train  valid  [tensor(-0.0603, dtype=torch.float16), tensor(...  \n",
       "101310    test  train  [tensor(-0.0255, dtype=torch.float16), tensor(...  \n",
       "27388    valid   test  [tensor(-0.0048, dtype=torch.float16), tensor(...  \n",
       "28735    train  train  [tensor(-0.0266, dtype=torch.float16), tensor(...  \n",
       "14648    train  train  [tensor(-0.0038, dtype=torch.float16), tensor(...  \n",
       "...        ...    ...                                                ...  \n",
       "140138   train  train  [tensor(-0.0692, dtype=torch.float16), tensor(...  \n",
       "132646   valid   test  [tensor(0.0010, dtype=torch.float16), tensor(0...  \n",
       "145951   train  train  [tensor(0.0049, dtype=torch.float16), tensor(-...  \n",
       "146264   train  valid  [tensor(-0.0703, dtype=torch.float16), tensor(...  \n",
       "120246   valid   test  [tensor(-0.0141, dtype=torch.float16), tensor(...  \n",
       "\n",
       "[328 rows x 41 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.cohere_0 == 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60a3b5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1024])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(all_embeddings[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0aa17c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = list(torch.tensor(all_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f402edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e0f5cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0133, -0.0096, -0.0671,  ...,  0.0381, -0.0674, -0.0093],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor(all_embeddings[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c694897d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6765a7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cohere_0\n",
       "train    100362\n",
       "test      27356\n",
       "valid     25091\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cohere_0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4e2326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    87632\n",
       "0    65177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b8b4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'MT5Tokenizer'.\n"
     ]
    }
   ],
   "source": [
    "embedder = MT5EmbedderAdvanced(model_name=\"google/mt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692d069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda17ea8cf55418693a12c9fe2b2d4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/152809 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "You have to specify either decoder_input_ids or decoder_inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embeddings = \u001b[43membedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_batch_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36mMT5EmbedderAdvanced.get_batch_embeddings\u001b[39m\u001b[34m(self, texts, batch_size, max_length, pooling, show_progress, normalize)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# Get embeddings\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     batch_embeddings = \u001b[38;5;28mself\u001b[39m._pool_embeddings(\n\u001b[32m    108\u001b[39m         outputs.last_hidden_state,\n\u001b[32m    109\u001b[39m         inputs[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    110\u001b[39m         pooling=pooling\n\u001b[32m    111\u001b[39m     )\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/base/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/base/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/base/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1551\u001b[39m, in \u001b[36mMT5Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1548\u001b[39m         decoder_attention_mask = decoder_attention_mask.to(\u001b[38;5;28mself\u001b[39m.decoder.first_device)\n\u001b[32m   1550\u001b[39m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m   1568\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs + encoder_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/base/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/base/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/base/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:975\u001b[39m, in \u001b[36mMT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    974\u001b[39m     err_msg_prefix = \u001b[33m\"\u001b[39m\u001b[33mdecoder_\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_decoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m975\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou have to specify either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33minput_ids or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33minputs_embeds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m    978\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[31mValueError\u001b[39m: You have to specify either decoder_input_ids or decoder_inputs_embeds"
     ]
    }
   ],
   "source": [
    "embeddings = embedder.get_batch_embeddings(\n",
    "    texts=df.text.tolist(),\n",
    "    batch_size=32,\n",
    "    pooling=\"mean\",\n",
    "    normalize=True,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4fe086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model_link: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14051742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1215b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61797 entries, 0 to 61796\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    61797 non-null  object\n",
      " 1   label   61797 non-null  object\n",
      " 2   domain  61797 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca168d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "human_text      34713\n",
       "machine_text    27084\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe7f6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '- Strengths:\\n* Outperforms ALIGN in supervised entity linking task which suggests that the\\nproposed framework improves representations of text and knowledge that are\\nlearned jointly.\\n* Direct comparison with closely related approach using very similar input\\ndata.\\n* Analysis of the smoothing parameter provides useful analysis since impact of\\npopularity is a persistent issue in entity linking.\\n\\n- Weaknesses:\\n* Comparison with ALIGN could be better. ALIGN used content window size 10 vs\\nthis paper\\'s 5, vector dimension of 500 vs this paper\\'s 200. Also its not clear\\nto me whether N(e_j) includes only entities that link to e_j. The graph is\\ndirected and consists of wikipedia outlinks, but is adjacency defined as it\\nwould be for an undirected graph? For ALIGN, the context of an entity is the\\nset of entities that link to that entity. If N(e_j) is different, we cannot\\ntell how much impact this change has on the learned vectors, and this could\\ncontribute to the difference in scores on the entity similarity task. \\n* It is sometimes difficult to follow whether \"mention\" means a string type, or\\na particular mention in a particular document. The phrase \"mention embedding\"\\nis used, but it appears that embeddings are only learned for mention senses.\\n* It is difficult to determine the impact of sense disambiguation order without\\ncomparison to other unsupervised entity linking methods. \\n\\n- General Discussion:',\n",
       " 'label': 'human_text',\n",
       " 'domain': 'human'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49db9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import M4GTDataModule\n",
    "\n",
    "data_module = M4GTDataModule(\n",
    "    train_data_dir=  'data_correct.json',\n",
    "    val_data_dir= 'data_correct.json',\n",
    "    test_data_dir= 'data_correct.json',\n",
    "    predict_data_dir= 'data_correct.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51cbfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LigthningClassifier\n",
    "\n",
    "module = LigthningClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d988debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "trainer = L.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(module, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7544f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n",
      "Failed to retrieve folder contents\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "gdown.download_folder(id=\"1HQkWneHuno5cnvHC2obWaNUPaSEtfGQ1\", output=\".\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71556311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project-zy5VbVj4-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
